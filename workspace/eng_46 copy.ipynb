{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219c90df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a professional crypto market analyst trained as a structured language model. Your role is to process cryptocurrency‑related news and generate structured, machine‑readable insights. Your task is to enrich input JSON with structured information about the event, including standardized entities, neutral descriptions, related tickers, tags, potential impacts, and directional sentiment analysis.\n",
      "\n",
      "Objective\n",
      "\n",
      "Given the input JSON, perform the following tasks:\n",
      "\t1.\tExtract and standardize key entities mentioned in the news.\n",
      "\t•\tFollow the standardization guidelines below.\n",
      "\t•\tAvoid overly specific entities occurring rarely; group them under more general entities when appropriate.\n",
      "\t2.\tAssign 5 – 10 relevant tags to each entity that indicate its broader category or relationship.\n",
      "\t3.\tGenerate a concise, neutral, context‑independent sentence describing each standardized entity.\n",
      "\t•\t10 – 25 words.\n",
      "\t•\tFactual and objective (no opinion or sentiment).\n",
      "\t•\tSuitable for use as an embedding in clustering.\n",
      "\t4.\tIdentify token tickers directly or indirectly related to the event.\n",
      "\t5.\tAnalyze potential impacts on each standardized entity and ticker.\n",
      "\t6.\tDetermine directional sentiment relationships:\n",
      "\t•\tInclude both a source entity (“from”) and a target entity or ticker (“to”).\n",
      "\t•\tIf the sentiment is a general opinion from the article, use \"News\" as the source entity.\n",
      "\t•\tProvide\n",
      "\t•\t\"sentiment\": \"positive\" | \"negative\" | \"neutral\"\n",
      "\t•\t\"severity\": integer scale from ‑2 (strongly negative) to +2 (strongly positive)\n",
      "\t•\t\"confidence_score\": 0.0 – 1.0 based on clarity and context\n",
      "\n",
      "Entity Standardization Guidelines\n",
      "\t•\tU.S. Securities and Exchange Commission, SEC, U.S. Commodities and Futures Trading Commission, etc. → “U.S. Government Agency” with tags [\"U.S.\", \"Regulatory\"]\n",
      "\t•\tEl Salvador’s GDP → “El Salvador GDP” with tags [\"El Salvador\", \"GDP\", \"Small Country Economy\"]\n",
      "\t•\tMajor exchanges (e.g., Binance, Coinbase) → keep official names, tag as [\"Exchange\"]\n",
      "\t•\tKnown cryptocurrencies → use the official project name (e.g., “Ethereum” for ETH).\n",
      "\t•\tGeneric mentions (e.g., “European banks”) → standardize to a clear collective term (e.g., “European Banks”) and tag appropriately.\n",
      "\n",
      "Tag Standardization and Scope\n",
      "\t•\tUse 5–10 tags per entity.\n",
      "\t•\tAvoid tags that are too broad (“Global Finance”) or too narrow (“El Salvador GDP Growth Rate Q2 2025”).\n",
      "\t•\tPrefer existing categories: \"Regulatory\", \"Banks\", \"Exchange\", \"DeFi\", \"NFTs\", \"GDP\", \"Economy\", etc.\n",
      "\t•\tIf a prospective tag does not map neatly to an existing category and seems overly unique, generalize it or omit it.\n",
      "\n",
      "\n",
      "Output Format\n",
      "\n",
      "Return pure JSON with exactly the following structure (no additional keys, text, or commentary):\n",
      "\n",
      "{\n",
      "  \"entities\": [\n",
      "    {\n",
      "      \"name\": \"Standardized Entity Name\",\n",
      "      \"description\": \"Neutral one‑sentence description of the entity (10–25 words).\",\n",
      "      \"tags\": [\"tag1\", \"tag2\", \"tagN\", ...]\n",
      "    }\n",
      "  ],\n",
      "  \"sentiment\": [\n",
      "    {\n",
      "      \"from\": \"Standardized Source Entity (or \"News\")\",\n",
      "      \"to\": \"Standardized Target Entity or Ticker Name\",\n",
      "      \"sentiment\": \"positive|negative|neutral\",\n",
      "      \"severity\": -2,\n",
      "      \"confidence_score\": 0.0\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "Ensure the key order, casing, and data types match the schema exactly.\n",
      "\n",
      "\n",
      "\n",
      "title: United Parcel Service: A Value Buy On Strategic Transformation\n",
      "content: United Parcel Service: A Value Buy On Strategic Transformation UPS is a value Buy for long-term investors, with margin-driven upside potential but significant execution and macro risks to monitor. Key risks include Amazon volume loss, restructuring execution, tariff headwinds, and intensifying competition from FedEx and Amazon's logistics arm. Strategic healthcare logistics expansion and aggressive cost restructuring aim to offset revenue declines and drive higher long-term margins.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 106\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[38;5;66;03m# init llm runner\u001b[39;00m\n\u001b[32m    102\u001b[39m llmw = LLMW(openai_api_key, model=\u001b[33m\"\u001b[39m\u001b[33mgpt-4.1-nano\u001b[39m\u001b[33m\"\u001b[39m,max_concurrency=\u001b[32m1000\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m results = \u001b[43mllmw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnews_prompts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[38;5;28mprint\u001b[39m(results[\u001b[32m0\u001b[39m])\n\u001b[32m    111\u001b[39m     \u001b[38;5;66;03m# pprint(sources_count)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/ht/llm_api_wrapper/llmw/wrapper_v2.py:32\u001b[39m, in \u001b[36mLLMW.batch_call\u001b[39m\u001b[34m(self, prompts)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbatch_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, prompts):\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/law/lib/python3.11/asyncio/runners.py:186\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(main, debug)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[32m    162\u001b[39m \n\u001b[32m    163\u001b[39m \u001b[33;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    182\u001b[39m \u001b[33;03m    asyncio.run(main())\u001b[39;00m\n\u001b[32m    183\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m events._get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    185\u001b[39m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    187\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug=debug) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[32m    190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m runner.run(main)\n",
      "\u001b[31mRuntimeError\u001b[39m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "from typing import List, Dict, Tuple\n",
    "from pprint import pprint\n",
    "from types import new_class\n",
    "json_path = \"/Users/htplex/Developer/ht/llm_api_wrapper/workspace/[0] abelai_app_dev.json\"\n",
    "with open(json_path, 'r') as fp:\n",
    "    data = json.load(fp)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "prompt = \"\"\"\n",
    "You are a professional crypto market analyst trained as a structured language model. Your role is to process cryptocurrency‑related news and generate structured, machine‑readable insights. Your task is to enrich input JSON with structured information about the event, including standardized entities, neutral descriptions, related tickers, tags, potential impacts, and directional sentiment analysis.\n",
    "\n",
    "Objective\n",
    "\n",
    "Given the input JSON, perform the following tasks:\n",
    "\t1.\tExtract and standardize key entities mentioned in the news.\n",
    "\t•\tFollow the standardization guidelines below.\n",
    "\t•\tAvoid overly specific entities occurring rarely; group them under more general entities when appropriate.\n",
    "\t2.\tAssign 5 – 10 relevant tags to each entity that indicate its broader category or relationship.\n",
    "\t3.\tGenerate a concise, neutral, context‑independent sentence describing each standardized entity.\n",
    "\t•\t10 – 25 words.\n",
    "\t•\tFactual and objective (no opinion or sentiment).\n",
    "\t•\tSuitable for use as an embedding in clustering.\n",
    "\t4.\tIdentify token tickers directly or indirectly related to the event.\n",
    "\t5.\tAnalyze potential impacts on each standardized entity and ticker.\n",
    "\t6.\tDetermine directional sentiment relationships:\n",
    "\t•\tInclude both a source entity (“from”) and a target entity or ticker (“to”).\n",
    "\t•\tIf the sentiment is a general opinion from the article, use \"News\" as the source entity.\n",
    "\t•\tProvide\n",
    "\t•\t\"sentiment\": \"positive\" | \"negative\" | \"neutral\"\n",
    "\t•\t\"severity\": integer scale from ‑2 (strongly negative) to +2 (strongly positive)\n",
    "\t•\t\"confidence_score\": 0.0 – 1.0 based on clarity and context\n",
    "\n",
    "Entity Standardization Guidelines\n",
    "\t•\tU.S. Securities and Exchange Commission, SEC, U.S. Commodities and Futures Trading Commission, etc. → “U.S. Government Agency” with tags [\"U.S.\", \"Regulatory\"]\n",
    "\t•\tEl Salvador’s GDP → “El Salvador GDP” with tags [\"El Salvador\", \"GDP\", \"Small Country Economy\"]\n",
    "\t•\tMajor exchanges (e.g., Binance, Coinbase) → keep official names, tag as [\"Exchange\"]\n",
    "\t•\tKnown cryptocurrencies → use the official project name (e.g., “Ethereum” for ETH).\n",
    "\t•\tGeneric mentions (e.g., “European banks”) → standardize to a clear collective term (e.g., “European Banks”) and tag appropriately.\n",
    "\n",
    "Tag Standardization and Scope\n",
    "\t•\tUse 5–10 tags per entity.\n",
    "\t•\tAvoid tags that are too broad (“Global Finance”) or too narrow (“El Salvador GDP Growth Rate Q2 2025”).\n",
    "\t•\tPrefer existing categories: \"Regulatory\", \"Banks\", \"Exchange\", \"DeFi\", \"NFTs\", \"GDP\", \"Economy\", etc.\n",
    "\t•\tIf a prospective tag does not map neatly to an existing category and seems overly unique, generalize it or omit it.\n",
    "\n",
    "\n",
    "Output Format\n",
    "\n",
    "Return pure JSON with exactly the following structure (no additional keys, text, or commentary):\n",
    "\n",
    "{\n",
    "  \"entities\": [\n",
    "    {\n",
    "      \"name\": \"Standardized Entity Name\",\n",
    "      \"description\": \"Neutral one‑sentence description of the entity (10–25 words).\",\n",
    "      \"tags\": [\"tag1\", \"tag2\", \"tagN\", ...]\n",
    "    }\n",
    "  ],\n",
    "  \"sentiment\": [\n",
    "    {\n",
    "      \"from\": \"Standardized Source Entity (or \\\"News\\\")\",\n",
    "      \"to\": \"Standardized Target Entity or Ticker Name\",\n",
    "      \"sentiment\": \"positive|negative|neutral\",\n",
    "      \"severity\": -2,\n",
    "      \"confidence_score\": 0.0\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "Ensure the key order, casing, and data types match the schema exactly.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "news_prompts = [\n",
    "    prompt + \"\\n\\n\" + \"title: {}\\ncontent: {}\".format(d[\"title\"], d[\"text\"])\n",
    "    for d in data\n",
    "]\n",
    "print(news_prompts[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from glob import glob\n",
    "from os.path import join\n",
    "import json\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import os\n",
    "from os.path import expanduser\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from llmw.wrapper_v2 import LLMW\n",
    "\n",
    "# api key\n",
    "\n",
    "# init llm runner\n",
    "model = \"gpt-5\"\n",
    "llmw = LLMW(openai_api_key, model=model,max_concurrency=1000)\n",
    "\n",
    "\n",
    "\n",
    "results = llmw.batch_call(news_prompts)\n",
    "print(results[0])\n",
    "            \n",
    "\n",
    "\n",
    "    # pprint(sources_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bacb3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4704\n",
      "4704\n",
      "4704\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "1\n",
      "1\n",
      "1\n",
      "Score 0: 23.31% (31/133)\n",
      "Score 1: 44.15% (891/2018)\n",
      "Score 2: 44.79% (1376/3072)\n",
      "Score 3: 24.63% (285/1157)\n",
      "Score 4: 21.71% (71/327)\n",
      "Score 5: 6.82% (3/44)\n",
      "None\n",
      "Score 0: 44.93% (62/138)\n",
      "Score 1: 56.39% (1098/1947)\n",
      "Score 2: 52.25% (1438/2752)\n",
      "Score 3: 36.69% (419/1142)\n",
      "Score 4: 29.51% (85/288)\n",
      "Score 5: 2.63% (1/38)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "# json_path = \"/Users/htplex/Developer/ht/llm_api_wrapper/workspace/eng_46_answers_v3.json\"\n",
    "# with open(json_path, 'r') as fp:\n",
    "#     ai_scores = json.load(fp)\n",
    "# print(len(ai_scores))\n",
    "# print(len(machine_scores))\n",
    "# print(len(rp_scores))\n",
    "# ai_scores_post = []\n",
    "# for i in range(len(ai_scores)):\n",
    "#     if type(ai_scores[i]) == str:\n",
    "#         try:\n",
    "#             ai_scores_post.append(int(ai_scores[i]))\n",
    "#         except:\n",
    "#             ai_scores_post.append(5)\n",
    "#             print(5)\n",
    "        \n",
    "#     else:\n",
    "#         ai_scores_post.append(ai_scores[i])\n",
    "# ai_scores = ai_scores_post\n",
    "\n",
    "\n",
    "# ai_scores = [int(str(x)) for x in ai_scores]\n",
    "# machine_scores = [int(str(int(float(x)))) for x in machine_scores]\n",
    "# rp_scores = [int(str(x)) for x in rp_scores]\n",
    "\n",
    "# ai_scores = [(x-1)//3+1 for x in ai_scores]\n",
    "# machine_scores = [(x-1)//3+1 for x in machine_scores]\n",
    "# rp_scores = [(x-1)//3+1 for x in rp_scores]\n",
    "\n",
    "# print(ai_scores[0])\n",
    "# print(machine_scores[0])\n",
    "# print(rp_scores[0])\n",
    "\n",
    "# def print_same_score_percentage_per_score(list1, list2):\n",
    "#     \"\"\"\n",
    "#     Print the percentage of same scores for each unique score in list1 and list2.\n",
    "#     \"\"\"\n",
    "#     if len(list1) != len(list2):\n",
    "#         raise ValueError(\"Score lists must have the same length.\")\n",
    "#     from collections import Counter\n",
    "\n",
    "#     scores = sorted(set(str(x) for x in list1) | set(str(y) for y in list2), key=lambda x: int(x))\n",
    "#     for score in scores:\n",
    "#         total = sum(1 for a, b in zip(list1, list2) if str(a) == score or str(b) == score)\n",
    "#         same = sum(1 for a, b in zip(list1, list2) if str(a) == str(b) == score)\n",
    "#         percent = (same / total) if total else 0\n",
    "#         print(f\"Score {score}: {percent:.2%} ({same}/{total})\")\n",
    "\n",
    "# print(print_same_score_percentage_per_score(ai_scores, rp_scores))\n",
    "# print(print_same_score_percentage_per_score(machine_scores, rp_scores))\n",
    "\n",
    "\n",
    "# # Score 0: 49.76% (1021/2052)\n",
    "# # Score 1: 44.79% (1376/3072)\n",
    "# # Score 2: 24.63% (285/1157)\n",
    "# # Score 3: 21.71% (71/327)\n",
    "# # Score 4: 6.82% (3/44)\n",
    "# # None\n",
    "# # Score 0: 61.52% (1236/2009)\n",
    "# # Score 1: 52.25% (1438/2752)\n",
    "# # Score 2: 36.69% (419/1142)\n",
    "# # Score 3: 29.51% (85/288)\n",
    "# # Score 4: 2.63% (1/38)\n",
    "\n",
    "# # match_bands(ai_scores, rp_scores)\n",
    "\n",
    "# # Per-human-band agreement:\n",
    "# # Band 0: 71.26% —>60.78% \n",
    "# # Band 2: 78.21% —>70.27%\n",
    "# # Band 5: 62.52% —>53.79%\n",
    "# # Band 8: 56.24% —>45.53%\n",
    "# # Band 11: 51.20% —>37.17%\n",
    "# # Band 14: 50.00% —>30.00%\n",
    "\n",
    "\n",
    "# # match_bands(machine_scores, rp_scores)\n",
    "\n",
    "# # Per-human-band agreement:\n",
    "# # Band 0: 71.26%\n",
    "# # Band 2: 78.21%\n",
    "# # Band 5: 62.52%\n",
    "# # Band 8: 56.24%\n",
    "# # Band 11: 51.20%\n",
    "# # Band 14: 50.00%\n",
    "\n",
    "\n",
    "# Score 0:  44.93% -> 23.31%\n",
    "# Score 2: 56.39% -> 44.15%\n",
    "# Score 5: 52.25% ->44.79%\n",
    "# Score 8: 36.69% -> 24.63%\n",
    "# Score 11: 29.51% -> 21.71%\n",
    "# Score 14: 2.63% -> 6.82%\n",
    "\n",
    "\n",
    "# None\n",
    "# Score 0:\n",
    "# Score 1:  \n",
    "# Score 2: \n",
    "# Score 3: \n",
    "# Score 4: \n",
    "# Score 5: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e24930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples   : 7\n",
      "Exact-band match: 5\n",
      "Agreement rate  : 71.4286%\n",
      "\n",
      "Confusion matrix (rows = human band, cols = machine band):\n",
      "HB/MB\t0\t2\t5\t8\t11\t14\n",
      "0\t1\t0\t0\t0\t0\t0\n",
      "2\t0\t1\t0\t0\t0\t0\n",
      "5\t0\t1\t0\t0\t0\t0\n",
      "8\t0\t0\t1\t1\t0\t0\n",
      "11\t0\t0\t0\t0\t1\t0\n",
      "14\t0\t0\t0\t0\t0\t1\n",
      "\n",
      "Per-human-band agreement:\n",
      "Band 0: 100.00%\n",
      "Band 2: 100.00%\n",
      "Band 5: 0.00%\n",
      "Band 8: 50.00%\n",
      "Band 11: 100.00%\n",
      "Band 14: 100.00%\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "# --- helper ---------------------------------------------------------------\n",
    "\n",
    "def _band(score: int) -> int:\n",
    "    \"\"\"Map a raw score to its rating band.\"\"\"\n",
    "    if score >= 13:\n",
    "        return 14\n",
    "    if score >= 10:\n",
    "        return 11\n",
    "    if score >= 7:\n",
    "        return 8\n",
    "    if score >= 4:\n",
    "        return 5\n",
    "    if score >= 1:\n",
    "        return 2\n",
    "    return 0\n",
    "\n",
    "\n",
    "# --- main API -------------------------------------------------------------\n",
    "\n",
    "def match_bands(\n",
    "    human_scores: List[int | float],\n",
    "    machine_scores: List[int | float],\n",
    "    *,\n",
    "    bands_order: Tuple[int, ...] = (0, 2, 5, 8, 11, 14),\n",
    "    verbose: bool = True,\n",
    ") -> Dict[str, object]:\n",
    "    \"\"\"\n",
    "    Compare two aligned lists of scores, bucket them into bands, and compute:\n",
    "      • overall agreement count / rate\n",
    "      • a confusion-matrix dict  {(human_band, machine_band): count}\n",
    "      • per-human-band agreement rates\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    human_scores   : list[int | float]\n",
    "        Raw scores from human raters.\n",
    "    machine_scores : list[int | float]\n",
    "        Raw scores from the model / system, same length and order as `human_scores`.\n",
    "    bands_order    : tuple[int, ...]\n",
    "        The band labels to show in the confusion matrix (default mirrors original script).\n",
    "    verbose        : bool\n",
    "        If True (default) prints a report; otherwise returns data silently.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict with keys\n",
    "        total, same, agreement, confusion, per_band\n",
    "    \"\"\"\n",
    "    if len(human_scores) != len(machine_scores):\n",
    "        raise ValueError(\"Input lists must have the same length.\")\n",
    "\n",
    "    total = same = 0\n",
    "    confusion: Dict[Tuple[int, int], int] = defaultdict(int)\n",
    "\n",
    "    # --- accumulate statistics -------------------------------------------\n",
    "    for h_raw, m_raw in zip(human_scores, machine_scores):\n",
    "        try:\n",
    "            h_band = _band(int(h_raw))\n",
    "            m_band = _band(int(m_raw))\n",
    "        except (TypeError, ValueError):\n",
    "            # skip unparseable entries\n",
    "            continue\n",
    "\n",
    "        total += 1\n",
    "        if h_band == m_band:\n",
    "            same += 1\n",
    "        confusion[(h_band, m_band)] += 1\n",
    "\n",
    "    if total == 0:\n",
    "        raise ValueError(\"No valid score pairs processed.\")\n",
    "\n",
    "    agreement = same / total\n",
    "    per_band: Dict[int, float] = {}\n",
    "    for hb in bands_order:\n",
    "        row_total = sum(confusion.get((hb, mb), 0) for mb in bands_order)\n",
    "        per_band[hb] = (confusion.get((hb, hb), 0) / row_total) if row_total else 0.0\n",
    "\n",
    "    # --- optionally print -------------------------------------------------\n",
    "    if verbose:\n",
    "        print(f\"Total samples   : {total}\")\n",
    "        print(f\"Exact-band match: {same}\")\n",
    "        print(f\"Agreement rate  : {agreement:.4%}\\n\")\n",
    "\n",
    "        # confusion matrix header\n",
    "        header = \"HB/MB\\t\" + \"\\t\".join(map(str, bands_order))\n",
    "        print(\"Confusion matrix (rows = human band, cols = machine band):\")\n",
    "        print(header)\n",
    "        for hb in bands_order:\n",
    "            row = [str(confusion.get((hb, mb), 0)) for mb in bands_order]\n",
    "            print(f\"{hb}\\t\" + \"\\t\".join(row))\n",
    "\n",
    "        # per-band agreement\n",
    "        print(\"\\nPer-human-band agreement:\")\n",
    "        for hb in bands_order:\n",
    "            print(f\"Band {hb}: {per_band[hb]:.2%}\")\n",
    "\n",
    "    # --- return structured data ------------------------------------------\n",
    "    return {\n",
    "        \"total\": total,\n",
    "        \"same\": same,\n",
    "        \"agreement\": agreement,\n",
    "        \"confusion\": dict(confusion),\n",
    "        \"per_band\": per_band,\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabacb1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "law",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
